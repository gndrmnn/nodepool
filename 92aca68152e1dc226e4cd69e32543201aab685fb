{
  "comments": [
    {
      "unresolved": false,
      "key": {
        "uuid": "40f3f878_355dfa01",
        "filename": "/PATCHSET_LEVEL",
        "patchSetId": 2
      },
      "lineNbr": 0,
      "author": {
        "id": 33934
      },
      "writtenOn": "2022-03-10T17:26:54Z",
      "side": 1,
      "message": "Is this what you had in mind?",
      "revId": "92aca68152e1dc226e4cd69e32543201aab685fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "8e6308b9_307f2432",
        "filename": "nodepool/driver/openstack/handler.py",
        "patchSetId": 2
      },
      "lineNbr": 302,
      "author": {
        "id": 4146
      },
      "writtenOn": "2022-03-14T16:12:52Z",
      "side": 1,
      "message": "I think this long sleep is why the testing fails. We probably check states before this sleep is completed.\n\nAs far as implementing the sleep I wonder if we need to do a hybrid between the current pause and the sleeping with retries to ensure we don\u0027t end up with a provider that grabs all the node requests but they fail for a long time due to quota errors. Something like having the first node to hit a quota error continue to retry but pause all other requests? That should provide the request pressure you want against the API while also avoiding having a single provider take all requests then fail to service them due to quotas.",
      "revId": "92aca68152e1dc226e4cd69e32543201aab685fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "73a226b5_2520071a",
        "filename": "nodepool/driver/openstack/handler.py",
        "patchSetId": 2
      },
      "lineNbr": 302,
      "author": {
        "id": 33934
      },
      "writtenOn": "2022-03-22T15:29:23Z",
      "side": 1,
      "message": "I did some digging, and I don\u0027t think it would take all the requests. My understanding from reading the code is that only the requests that race in `_waitForNodeSet` checking the quota would enter this loop. The requests after that will automatically pause the handler (especially since we invalidate the quota cache). I don\u0027t think any \"pausing\" is necessary here since the code in `_waitForNodeSet` handles that already; the only thing we could *maybe* do here is try and detect if multiple threads are in this loop because of quota reasons and kick all but one out.... but this seems complex and error prone so I\u0027d rather not unless it\u0027s a huge problem to have a few nodes in the loop until quota is satisfied (realizing that it won\u0027t consume all nodes because of the reasons stated above).\n\n\nIf my understanding is incorrect, please let me know :)",
      "parentUuid": "8e6308b9_307f2432",
      "revId": "92aca68152e1dc226e4cd69e32543201aab685fb",
      "serverId": "4a232e18-c5a9-48ee-94c0-e04e7cca6543"
    }
  ]
}